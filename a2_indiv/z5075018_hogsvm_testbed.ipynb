{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time\n",
    "from skimage import io\n",
    "from skimage.feature import hog\n",
    "#from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,15)\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'Individual_Component'\n",
    "SEED = 42\n",
    "\n",
    "# [HOG parameters]\n",
    "# img (w,h): (64,80)\n",
    "# NFEATURES = nblocks * norientations/cell * ncells/block\n",
    "BLOCK_NORM_LIST = ['L1', 'L1-sqrt', 'L2', 'L2-Hys']\n",
    "BLOCK_SIZE_LIST = [1, 2, 3, 4, 5, 6]\n",
    "CELL_PIXEL_LIST = [4, 6, 7, 8, 9, 10, 12, 14, 16]\n",
    "ORIENTATION_LIST = [6, 8, 9, 10, 12, 16, 32]\n",
    "\n",
    "NPOS_TRAINING_IMGS = 10#3000\n",
    "NNEG_TRAINING_IMGS = 10#3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def list_mul(l, num):\n",
    "    return tuple(map(lambda x: int(num * x), l))\n",
    "\n",
    "# Histogram of Oriented Gradients\n",
    "def run_hog(img, visualize=False):\n",
    "    global NORIENTATIONS, CELL_PIXELSHAPE, CELLS_PER_BLOCK, BLOCK_NORM\n",
    "    result = hog(img, orientations=NORIENTATIONS, \n",
    "                 pixels_per_cell=CELL_PIXELSHAPE, cells_per_block=CELLS_PER_BLOCK, \n",
    "                 block_norm=BLOCK_NORM, visualize=visualize, transform_sqrt=True,\n",
    "                 multichannel=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/manikg/training-svm-classifier-with-hog-features\n",
    "\n",
    "RESULTS_FH = None # global\n",
    "\n",
    "def log_result(s):\n",
    "    global RESULTS_FH\n",
    "    print(s)\n",
    "    print(file=RESULTS_FH)\n",
    "    \n",
    "\n",
    "# Code to load the dataset\n",
    "def get_dataset_fp(is_train):\n",
    "    if is_train:\n",
    "        subroot = 'train'\n",
    "    else:\n",
    "        subroot = 'test'\n",
    "    base_fp = os.path.join(DIR, subroot)\n",
    "    pos_dirs = []\n",
    "    neg_dirs = []\n",
    "    for dir_name in os.listdir(base_fp): # all files & dirs\n",
    "        subfp = os.path.join(base_fp, dir_name)\n",
    "        if not os.path.isdir(subfp):\n",
    "            continue    \n",
    "        for subdir_name in os.listdir(subfp):\n",
    "            subsubfp = os.path.join(subfp, subdir_name)\n",
    "            if not os.path.isdir(subsubfp):\n",
    "                continue\n",
    "            if 'positive' in dir_name:\n",
    "                pos_dirs.append(subsubfp)\n",
    "            elif 'negative' in dir_name:\n",
    "                neg_dirs.append(subsubfp)\n",
    "    return pos_dirs, neg_dirs\n",
    "\n",
    "def get_subset_images(fp, nimgs=None, preproc=False):\n",
    "    results = []\n",
    "    results_fp = []\n",
    "    count = 0\n",
    "    for img_fn in os.listdir(fp):\n",
    "        img_fp = os.path.join(fp, img_fn)\n",
    "        if os.path.isdir(img_fp) or img_fn[-4:].lower() != '.pnm':\n",
    "            continue\n",
    "        img = io.imread(img_fp)\n",
    "        if preproc: # proprocess as HOG\n",
    "            hog_fd = run_hog(img)\n",
    "            results.append(hog_fd)\n",
    "        else:\n",
    "            results.append(img)\n",
    "        results_fp.append(img_fp)\n",
    "        count += 1 # restrict num imgs loaded\n",
    "        if nimgs != None and count >= nimgs:\n",
    "            break\n",
    "    return results, results_fp\n",
    "\n",
    "NO_PERSON = 0\n",
    "IS_PERSON = 1\n",
    "\n",
    "def load_images(is_train, shuffle, npos_imgs=None, nneg_imgs=None, save_fn=None):\n",
    "    pos_dirs, neg_dirs = get_dataset_fp(is_train=is_train)    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    fp_train = []\n",
    "    # get preprocessed training/testing data\n",
    "    for fp in pos_dirs:\n",
    "        start_time = time.time()\n",
    "        cur_subset, cur_subset_fp = get_subset_images(fp, npos_imgs, True)\n",
    "        x_train += cur_subset\n",
    "        fp_train += cur_subset_fp\n",
    "        log_result('  * {:.3f}s runtime (images loaded): {}'.format(time.time() - start_time,fp))\n",
    "        if npos_imgs != None:\n",
    "            npos_imgs -= len(cur_subset)\n",
    "            if npos_imgs <= 0:\n",
    "                break\n",
    "    pos_length = len(x_train)\n",
    "    y_train += [IS_PERSON] * pos_length\n",
    "    \n",
    "    for fp in neg_dirs:\n",
    "        start_time = time.time()\n",
    "        cur_subset, cur_subset_fp = get_subset_images(fp, nneg_imgs, True)\n",
    "        x_train += cur_subset\n",
    "        fp_train += cur_subset_fp\n",
    "        log_result('  * {:.3f}s runtime (images loaded): {}'.format(time.time() - start_time,fp))\n",
    "        if nneg_imgs != None:\n",
    "            nneg_imgs -= len(cur_subset)\n",
    "            if nneg_imgs <= 0:\n",
    "                break\n",
    "    y_train += [NO_PERSON] * (len(x_train) - pos_length)\n",
    "    \n",
    "    # get hog descriptor size\n",
    "    hog_shape = x_train[0].shape\n",
    "    \n",
    "    # shuffle training data\n",
    "    #print('Reformatting data...')\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    fp_train_index = np.arange(len(fp_train)) # create unique IDs (from 0)\n",
    "    \n",
    "    if shuffle:\n",
    "        y_train = y_train.reshape(len(y_train),1)\n",
    "        fp_train_index = fp_train_index.reshape(len(fp_train_index),1)\n",
    "        \n",
    "        data_frame = np.hstack((x_train,y_train, fp_train_index))\n",
    "        #print('Reshuffling data...')\n",
    "        start_time = time.time()\n",
    "        np.random.seed(SEED)\n",
    "        np.random.shuffle(data_frame)\n",
    "        x_train = data_frame[:,:-2]\n",
    "        y_train = data_frame[:,-2].ravel()\n",
    "        fp_train_index = data_frame[:,-1].ravel()\n",
    "        log_result('  * {:.3f}s runtime (shuffling)'.format(time.time() - start_time))\n",
    "    \n",
    "    log_result('HOG descriptor size: ' + str(hog_shape))\n",
    "    result = (x_train, y_train, fp_train_index, fp_train)\n",
    "    # save loaded images\n",
    "    if save_fn != None:\n",
    "        with open(save_fn, 'wb') as fh:\n",
    "            pickle.dump(result, fh)\n",
    "    return result\n",
    "    \n",
    "# Code to generate the SVM model\n",
    "def gen_model(model_fn, x_train, y_train):\n",
    "    # generate SVM model\n",
    "    start_time = time.time()\n",
    "    #clf = svm.SVC(probability=True)\n",
    "    clf = linear_model.SGDClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    log_result('{:.3f}s runtime (SGD training)'.format(time.time() - start_time))\n",
    "    \n",
    "    # save SVM model\n",
    "    with open(model_fn, 'wb') as fh:\n",
    "        pickle.dump(clf, fh)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes statistics for the classifier's performance\n",
    "def run_test(clf, x_test, y_test):\n",
    "    log_result('\\n[Classifier statistics]:')\n",
    "    start_time = time.time()\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_prob = clf.predict_proba(x_test)\n",
    "    # y_prob: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "    #  - shape: (nsamples, nclasses), by order of `clf.classes_`\n",
    "    elapsed_time = time.time() - start_time\n",
    "    log_result('  * {:.3f}s prediction time ({:.6f} s/image)'.format(elapsed_time, elapsed_time/len(y_test)))\n",
    "    log_result('  * AUC (weighted): {:.3f}'.format(metrics.roc_auc_score(y_test, y_prob[:,IS_PERSON], average='weighted')))\n",
    "    log_result('  * Accuracy: {:.3f}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "    log_result('  * Precision (weighted): {:.3f}'.format(metrics.precision_score(y_test, y_pred, average='weighted')))\n",
    "    log_result('  * Recall (weighted): {:.3f}'.format(metrics.recall_score(y_test, y_pred, average='weighted')))\n",
    "    log_result('  * Confusion Matrix:')\n",
    "    log_result(str(metrics.confusion_matrix(y_test, y_pred)))\n",
    "    return y_pred, y_prob\n",
    "\n",
    "# Returns all image file paths detected falsely\n",
    "def filter_failed_fp(y_pred, y_test, fp_test_index, fp_test):\n",
    "    failed_fp = []\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] != y_test[i]:\n",
    "            if y_pred[i] == NO_PERSON:\n",
    "                label = 'FN'\n",
    "            else:\n",
    "                label = 'FP'\n",
    "            failed_fp.append( (label, fp_test[int(fp_test_index[i])]) )\n",
    "    return failed_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate SVM model (and training images) or load cached result\n",
    "def get_svm_model(cur_dir_contents, SVM_MODEL, PRE_TRAINING_IMGS):\n",
    "    global NPOS_TRAINING_IMGS,NNEG_TRAINING_IMGS\n",
    "    if SVM_MODEL not in cur_dir_contents:\n",
    "        log_result('\\n[Training SVM model]:')\n",
    "        x_train, y_train, fp_train_index, fp_train = load_images(True,True, \n",
    "                                                                 NPOS_TRAINING_IMGS,NNEG_TRAINING_IMGS, \n",
    "                                                                 PRE_TRAINING_IMGS)\n",
    "        clf = gen_model(SVM_MODEL,x_train,y_train)\n",
    "    else:\n",
    "        log_result('\\n[Loading cached SVM model & training images]:')\n",
    "        with open(SVM_MODEL, 'rb') as fh:\n",
    "            clf = pickle.load(fh)\n",
    "        with open(PRE_TRAINING_IMGS, 'rb') as fh:\n",
    "            x_train, y_train, fp_train_index, fp_train = pickle.load(fh)\n",
    "            \n",
    "    log_result('Number of training images loaded:', len(x_train))\n",
    "    return x_train, y_train, fp_train_index, fp_train, clf\n",
    "\n",
    "# 2. Generate test images or load cached result\n",
    "def get_test_imgs(cur_dir_contents, PRE_TESTING_IMGS):\n",
    "    # Generate test images or load cached result\n",
    "    if PRE_TESTING_IMGS not in cur_dir_contents:\n",
    "        log_result('\\n[Generating test images]:')\n",
    "        x_test, y_test, fp_test_index, fp_test = load_images(False,True, save_fn=PRE_TESTING_IMGS)\n",
    "    else:\n",
    "        log_result('\\n[Loading cached test images]:')\n",
    "        with open(PRE_TESTING_IMGS, 'rb') as fh:\n",
    "            x_test, y_test, fp_test_index, fp_test = pickle.load(fh)\n",
    "    \n",
    "    log_result('Number of testing images loaded:', len(x_test))\n",
    "    return x_test, y_test, fp_test_index, fp_test\n",
    "            \n",
    "# 3. Evaluate performance (for all permutations)\n",
    "#    call: run_test()\n",
    "#    manual post-analysis: filter_failed_fp()\n",
    "\n",
    "# Wrapper for single iteration\n",
    "def run_hogsvm():\n",
    "    global NORIENTATIONS, CELL_PIXELSHAPE, CELLS_PER_BLOCK, BLOCK_NORM\n",
    "    global RESULTS_FH\n",
    "    base_fn = '_ori({})_cellpix({})_blksze({})_blknrm({})'.format(\n",
    "        NORIENTATIONS, CELL_PIXELSHAPE[0], CELLS_PER_BLOCK[0], BLOCK_NORM)\n",
    "    pickle_type = '.pickle'\n",
    "    text_type = '.txt'\n",
    "    SVM_MODEL = 'hogsvm_model' + base_fn + pickle_type\n",
    "    PRE_TRAINING_IMGS = 'hogsvm_train' + base_fn + pickle_type\n",
    "    PRE_TESTING_IMGS = 'hogsvm_test' + base_fn + pickle_type\n",
    "    results_fn = 'hogsvm_result' + base_fn + text_type\n",
    "    \n",
    "    cur_dir_contents = os.listdir('.')\n",
    "    RESULTS_FH = open(results_fn, 'w')\n",
    "    log_result('[Current parameter sweep]:')\n",
    "    log_result('Number of orientations: {}'.format(NORIENTATIONS))\n",
    "    log_result('Cell pixel shape: {}'.format(CELL_PIXELSHAPE))\n",
    "    log_result('Number of cells per block: {}'.format(CELLS_PER_BLOCK))\n",
    "    log_result('Block normalisation method: {}'.format(BLOCK_NORM))\n",
    "    \n",
    "    # load svm model and test dataset\n",
    "    x_train, y_train, fp_train_index, fp_train, clf = get_svm_model(cur_dir_contents, SVM_MODEL, PRE_TRAINING_IMGS)\n",
    "    x_test, y_test, fp_test_index, fp_test          = get_test_imgs(cur_dir_contents, PRE_TESTING_IMGS)\n",
    "    # evaluate on test and training datasets (as a crude check for overfitting)\n",
    "    y_pred, y_prob = run_test(clf, x_test, y_test)\n",
    "    y_pred_training, y_prob_training = run_test(clf, x_train, y_train)\n",
    "    # identify all false results\n",
    "    failed_fp = filter_failed_fp(y_pred, y_test, fp_test_index, fp_test)\n",
    "    log_result('\\n[Falsely detected images]:')\n",
    "    for label, fp in failed_fp:\n",
    "        log_result('  * {}: {}'.format(label,fp))\n",
    "\n",
    "    RESULTS_FH.close()\n",
    "    RESULTS_FH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [PARAMETER SWEEP]\n",
    "# block parameters\n",
    "for BLOCK_NORM in BLOCK_NORM_LIST:\n",
    "    for block_size in BLOCK_SIZE_LIST:\n",
    "        CELLS_PER_BLOCK = (block_size, block_size)    \n",
    "        # cell/orientation parameters\n",
    "        for cp in CELL_PIXEL_LIST:\n",
    "            CELL_PIXELSHAPE = (cp,cp)\n",
    "            for NORIENTATIONS in ORIENTATION_LIST:\n",
    "                run_hogsvm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
